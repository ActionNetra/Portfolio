{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30035,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-22T11:38:43.431123Z","iopub.execute_input":"2024-07-22T11:38:43.431539Z","iopub.status.idle":"2024-07-22T11:38:47.092183Z","shell.execute_reply.started":"2024-07-22T11:38:43.431499Z","shell.execute_reply":"2024-07-22T11:38:47.091213Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)  # Convert the data to a NumPy array\nm, n = data.shape  # Get the number of samples (m) and features (n)\nnp.random.shuffle(data)  # Shuffle the dataset to ensure randomness\n\n# Split data into development and training sets\ndata_dev = data[0:1000].T  # Take the first 1000 samples for development set and transpose\nY_dev = data_dev[0]  # Labels for the development set\nX_dev = data_dev[1:n]  # Features for the development set\nX_dev = X_dev / 255.  # Normalize pixel values to range [0, 1]\n\ndata_train = data[1000:m].T  # Use the remaining samples for training set and transpose\nY_train = data_train[0]  # Labels for the training set\nX_train = data_train[1:n]  # Features for the training set\nX_train = X_train / 255.  # Normalize pixel values to range [0, 1]\n_, m_train = X_train.shape  # Get the number of features and samples in the training set","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:30:24.556793Z","iopub.execute_input":"2024-07-22T12:30:24.557216Z","iopub.status.idle":"2024-07-22T12:30:25.319181Z","shell.execute_reply.started":"2024-07-22T12:30:24.557174Z","shell.execute_reply":"2024-07-22T12:30:25.318286Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def init_params():\n    \"\"\"\n    Initialize parameters for a 2-layer neural network.\n    Returns:\n        W1: Weight matrix for the first layer of shape (10, 784)\n        b1: Bias vector for the first layer of shape (10, 1)\n        W2: Weight matrix for the second layer of shape (10, 10)\n        b2: Bias vector for the second layer of shape (10, 1)\n    \"\"\"\n    W1 = np.random.rand(10, 784) - 0.5  # Random weights for the first layer\n    b1 = np.random.rand(10, 1) - 0.5  # Random biases for the first layer\n    W2 = np.random.rand(10, 10) - 0.5  # Random weights for the second layer\n    b2 = np.random.rand(10, 1) - 0.5  # Random biases for the second layer\n    return W1, b1, W2, b2\n\ndef ReLU(Z):\n    \"\"\"\n    Apply the ReLU activation function element-wise.\n    Args:\n        Z: Input matrix of shape (number of neurons, number of examples)\n    Returns:\n        Activated matrix where all negative values are set to zero\n    \"\"\"\n    return np.maximum(Z, 0)\n\ndef softmax(Z):\n    \"\"\"\n    Apply the softmax activation function to compute probabilities.\n    Args:\n        Z: Input matrix of shape (number of classes, number of examples)\n    Returns:\n        Probability matrix where each column sums to 1\n    \"\"\"\n    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # Subtract max for numerical stability\n    A = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)  # Compute softmax\n    return A\n\ndef forward_prop(W1, b1, W2, b2, X):\n    \"\"\"\n    Perform forward propagation through the network.\n    Args:\n        W1: Weight matrix for the first layer\n        b1: Bias vector for the first layer\n        W2: Weight matrix for the second layer\n        b2: Bias vector for the second layer\n        X: Input features matrix\n    Returns:\n        Z1: Linear combination output of the first layer\n        A1: Activation of the first layer after ReLU\n        Z2: Linear combination output of the second layer\n        A2: Activation of the second layer after softmax (final output)\n    \"\"\"\n    Z1 = W1.dot(X) + b1  # Compute linear combination for the first layer\n    A1 = ReLU(Z1)  # Apply ReLU activation function\n    Z2 = W2.dot(A1) + b2  # Compute linear combination for the second layer\n    A2 = softmax(Z2)  # Apply softmax activation function\n    return Z1, A1, Z2, A2\n\ndef ReLU_deriv(Z):\n    \"\"\"\n    Compute the derivative of the ReLU activation function.\n    Args:\n        Z: Input matrix\n    Returns:\n        Matrix indicating where Z was positive (1) or zero (0)\n    \"\"\"\n    return Z > 0\n\ndef one_hot(Y):\n    \"\"\"\n    Convert labels to one-hot encoded vectors.\n    Args:\n        Y: Vector of labels\n    Returns:\n        one_hot_Y: One-hot encoded matrix\n    \"\"\"\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1))  # Create a matrix of zeros\n    one_hot_Y[np.arange(Y.size), Y] = 1  # Set appropriate indices to 1\n    one_hot_Y = one_hot_Y.T  # Transpose to match required shape\n    return one_hot_Y\n\ndef backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n    \"\"\"\n    Perform backward propagation to compute gradients.\n    Args:\n        Z1: Linear combination output of the first layer\n        A1: Activation of the first layer\n        Z2: Linear combination output of the second layer\n        A2: Activation of the second layer (final output)\n        W1: Weight matrix for the first layer\n        W2: Weight matrix for the second layer\n        X: Input features matrix\n        Y: True labels\n    Returns:\n        dW1: Gradient of the weights for the first layer\n        db1: Gradient of the biases for the first layer\n        dW2: Gradient of the weights for the second layer\n        db2: Gradient of the biases for the second layer\n    \"\"\"\n    one_hot_Y = one_hot(Y)  # Convert true labels to one-hot encoded vectors\n    dZ2 = A2 - one_hot_Y  # Compute error term for the output layer\n    dW2 = 1 / m * dZ2.dot(A1.T)  # Compute gradient of weights for the second layer\n    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)  # Compute gradient of biases for the second layer\n    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)  # Compute error term for the hidden layer\n    dW1 = 1 / m * dZ1.dot(X.T)  # Compute gradient of weights for the first layer\n    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)  # Compute gradient of biases for the first layer\n    return dW1, db1, dW2, db2\n\ndef update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n    \"\"\"\n    Update parameters using gradient descent.\n    Args:\n        W1: Weight matrix for the first layer\n        b1: Bias vector for the first layer\n        W2: Weight matrix for the second layer\n        b2: Bias vector for the second layer\n        dW1: Gradient of the weights for the first layer\n        db1: Gradient of the biases for the first layer\n        dW2: Gradient of the weights for the second layer\n        db2: Gradient of the biases for the second layer\n        alpha: Learning rate\n    Returns:\n        Updated weights and biases\n    \"\"\"\n    W1 = W1 - alpha * dW1  # Update weights for the first layer\n    b1 = b1 - alpha * db1  # Update biases for the first layer\n    W2 = W2 - alpha * dW2  # Update weights for the second layer\n    b2 = b2 - alpha * db2  # Update biases for the second layer\n    return W1, b1, W2, b2\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:30:28.196994Z","iopub.execute_input":"2024-07-22T12:30:28.197368Z","iopub.status.idle":"2024-07-22T12:30:28.217202Z","shell.execute_reply.started":"2024-07-22T12:30:28.197335Z","shell.execute_reply":"2024-07-22T12:30:28.216203Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_predictions(A2):\n    \"\"\"\n    Get predicted class labels from the output activations.\n    Args:\n        A2: Final activation probabilities\n    Returns:\n        Array of predicted class labels\n    \"\"\"\n    return np.argmax(A2, axis=0)  # Get the index of the maximum value in each column\n\ndef get_accuracy(predictions, Y):\n    \"\"\"\n    Compute the accuracy of predictions compared to true labels.\n    Args:\n        predictions: Array of predicted class labels\n        Y: Array of true labels\n    Returns:\n        Accuracy as a proportion of correct predictions\n    \"\"\"\n    print(predictions, Y)  # Print predictions and true labels for debugging\n    return np.sum(predictions == Y) / Y.size  # Compute accuracy\n\ndef gradient_descent(X, Y, alpha, iterations):\n    \"\"\"\n    Perform gradient descent to optimize the neural network parameters.\n    \n    Args:\n        X: Input features matrix of shape (num_features, num_examples)\n        Y: True labels vector of shape (num_examples,)\n        alpha: Learning rate (float)\n        iterations: Number of iterations for gradient descent (int)\n    \n    Returns:\n        W1: Optimized weight matrix for the first layer\n        b1: Optimized bias vector for the first layer\n        W2: Optimized weight matrix for the second layer\n        b2: Optimized bias vector for the second layer\n    \"\"\"\n    # Initialize the parameters\n    W1, b1, W2, b2 = init_params()\n    \n    # Iterate through the number of specified iterations\n    for i in range(iterations):\n        # Perform forward propagation to get activations and linear combinations\n        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n        \n        # Perform backward propagation to get gradients\n        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n        \n        # Update the parameters using the gradients and learning rate\n        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n        \n        # Print the iteration number and accuracy every 50 iterations\n        if i % 50 == 0:\n            print(\"Iteration: \", i)\n            predictions = get_predictions(A2)\n            print(get_accuracy(predictions, Y))\n    \n    # Return the optimized parameters\n    return W1, b1, W2, b2\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:30:31.621437Z","iopub.execute_input":"2024-07-22T12:30:31.621804Z","iopub.status.idle":"2024-07-22T12:30:31.632112Z","shell.execute_reply.started":"2024-07-22T12:30:31.621773Z","shell.execute_reply":"2024-07-22T12:30:31.631014Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:30:57.519950Z","iopub.execute_input":"2024-07-22T12:30:57.520321Z","iopub.status.idle":"2024-07-22T12:31:39.605693Z","shell.execute_reply.started":"2024-07-22T12:30:57.520289Z","shell.execute_reply":"2024-07-22T12:31:39.604608Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Iteration:  0\n[0 0 0 ... 8 0 0] [8 7 3 ... 5 6 3]\n0.07221951219512195\nIteration:  10\n[3 4 3 ... 9 3 3] [8 7 3 ... 5 6 3]\n0.15909756097560976\nIteration:  20\n[3 4 3 ... 1 3 3] [8 7 3 ... 5 6 3]\n0.22931707317073172\nIteration:  30\n[3 4 3 ... 9 3 3] [8 7 3 ... 5 6 3]\n0.30209756097560975\nIteration:  40\n[3 4 3 ... 9 3 3] [8 7 3 ... 5 6 3]\n0.3631463414634146\nIteration:  50\n[3 6 3 ... 9 3 3] [8 7 3 ... 5 6 3]\n0.4228780487804878\nIteration:  60\n[1 6 3 ... 9 3 3] [8 7 3 ... 5 6 3]\n0.47573170731707315\nIteration:  70\n[1 6 3 ... 9 6 1] [8 7 3 ... 5 6 3]\n0.5225609756097561\nIteration:  80\n[1 4 3 ... 9 6 1] [8 7 3 ... 5 6 3]\n0.5598048780487805\nIteration:  90\n[8 4 3 ... 9 6 1] [8 7 3 ... 5 6 3]\n0.5930487804878048\nIteration:  100\n[8 4 3 ... 9 6 1] [8 7 3 ... 5 6 3]\n0.6185121951219512\nIteration:  110\n[8 4 3 ... 9 6 1] [8 7 3 ... 5 6 3]\n0.6407560975609756\nIteration:  120\n[8 4 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.6581707317073171\nIteration:  130\n[8 4 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.6743414634146342\nIteration:  140\n[8 4 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.6883658536585365\nIteration:  150\n[8 4 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7011219512195122\nIteration:  160\n[8 4 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.713\nIteration:  170\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7229512195121951\nIteration:  180\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.733\nIteration:  190\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7424146341463415\nIteration:  200\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7501707317073171\nIteration:  210\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7572439024390244\nIteration:  220\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7635853658536585\nIteration:  230\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7695609756097561\nIteration:  240\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7745121951219512\nIteration:  250\n[8 7 3 ... 8 6 1] [8 7 3 ... 5 6 3]\n0.7797073170731708\nIteration:  260\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.7841707317073171\nIteration:  270\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.7885365853658537\nIteration:  280\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.7928780487804878\nIteration:  290\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.7963414634146342\nIteration:  300\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.7993902439024391\nIteration:  310\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8023658536585366\nIteration:  320\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8053170731707318\nIteration:  330\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8086341463414635\nIteration:  340\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8115365853658537\nIteration:  350\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8144390243902438\nIteration:  360\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8166829268292682\nIteration:  370\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8194390243902439\nIteration:  380\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8215853658536585\nIteration:  390\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8237317073170731\nIteration:  400\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8254634146341463\nIteration:  410\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8272195121951219\nIteration:  420\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8289268292682926\nIteration:  430\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.830780487804878\nIteration:  440\n[8 7 3 ... 8 6 3] [8 7 3 ... 5 6 3]\n0.8326341463414634\nIteration:  450\n[8 7 3 ... 5 6 3] [8 7 3 ... 5 6 3]\n0.8340975609756097\nIteration:  460\n[8 7 3 ... 5 6 3] [8 7 3 ... 5 6 3]\n0.8357317073170731\nIteration:  470\n[8 7 3 ... 5 6 3] [8 7 3 ... 5 6 3]\n0.8367317073170731\nIteration:  480\n[8 7 3 ... 5 6 3] [8 7 3 ... 5 6 3]\n0.8380975609756097\nIteration:  490\n[8 7 3 ... 5 6 3] [8 7 3 ... 5 6 3]\n0.8393414634146341\n","output_type":"stream"}]},{"cell_type":"markdown","source":"~85% accuracy on training set.","metadata":{}},{"cell_type":"code","source":"ef make_predictions(X, W1, b1, W2, b2):\n    \"\"\"\n    Make predictions using the trained neural network model.\n    \n    Args:\n        X: Input features matrix of shape (num_features, num_examples)\n        W1: Weight matrix for the first layer\n        b1: Bias vector for the first layer\n        W2: Weight matrix for the second layer\n        b2: Bias vector for the second layer\n    \n    Returns:\n        predictions: Vector of predicted class labels\n    \"\"\"\n    # Perform forward propagation to get the final output activations\n    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n    \n    # Get the predicted class labels based on the output activations\n    predictions = get_predictions(A2)\n    \n    # Return the predictions\n    return predictions\n\ndef test_prediction(index, W1, b1, W2, b2):\n    \"\"\"\n    Test the model's prediction on a specific training example and display the image.\n    \n    Args:\n        index: Index of the training example to test\n        W1: Weight matrix for the first layer\n        b1: Bias vector for the first layer\n        W2: Weight matrix for the second layer\n        b2: Bias vector for the second layer\n    \"\"\"\n    # Get the specific training example's features\n    current_image = X_train[:, index, None]\n    \n    # Make a prediction using the trained model\n    prediction = make_predictions(current_image, W1, b1, W2, b2)\n    \n    # Get the true label for the training example\n    label = Y_train[index]\n    \n    # Print the prediction and the true label\n    print(\"Prediction: \", prediction)\n    print(\"Label: \", label)\n    \n    # Reshape and scale the image for display\n    current_image = current_image.reshape((28, 28)) * 255\n    \n    # Set the color map to gray and display the image\n    plt.gray()\n    plt.imshow(current_image, interpolation='nearest')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:37:43.158458Z","iopub.execute_input":"2024-07-22T12:37:43.158886Z","iopub.status.idle":"2024-07-22T12:37:43.168419Z","shell.execute_reply.started":"2024-07-22T12:37:43.158849Z","shell.execute_reply":"2024-07-22T12:37:43.167388Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Let's look at a couple of examples:","metadata":{}},{"cell_type":"code","source":"test_prediction(0, W1, b1, W2, b2)\ntest_prediction(1, W1, b1, W2, b2)\ntest_prediction(2, W1, b1, W2, b2)\ntest_prediction(3, W1, b1, W2, b2)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:37:49.798045Z","iopub.execute_input":"2024-07-22T12:37:49.798439Z","iopub.status.idle":"2024-07-22T12:37:50.548771Z","shell.execute_reply.started":"2024-07-22T12:37:49.798390Z","shell.execute_reply":"2024-07-22T12:37:50.547755Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Prediction:  [8]\nLabel:  8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Prediction:  [7]\nLabel:  7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Prediction:  [3]\nLabel:  3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Prediction:  [8]\nLabel:  8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Finally, let's find the accuracy on the dev set:","metadata":{}},{"cell_type":"code","source":"dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\nget_accuracy(dev_predictions, Y_dev)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T12:37:58.133303Z","iopub.execute_input":"2024-07-22T12:37:58.133749Z","iopub.status.idle":"2024-07-22T12:37:58.149149Z","shell.execute_reply.started":"2024-07-22T12:37:58.133708Z","shell.execute_reply":"2024-07-22T12:37:58.147946Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[8 9 6 5 4 8 2 6 0 7 9 4 8 0 6 0 5 7 2 1 5 0 8 1 8 3 6 4 2 9 3 2 9 3 4 7 6\n 3 0 3 6 4 8 4 7 6 0 7 1 7 1 0 9 8 2 8 0 6 6 8 8 0 2 8 8 1 8 5 0 9 9 6 6 2\n 6 9 9 0 3 0 6 0 9 8 9 2 0 8 5 6 6 3 6 8 0 0 0 6 6 4 1 3 5 7 8 8 4 1 6 7 9\n 0 2 7 3 8 0 3 1 2 9 2 4 5 8 4 0 5 0 9 4 0 7 0 2 9 7 0 7 0 3 4 1 0 1 9 7 5\n 7 9 7 7 7 1 1 4 0 2 4 8 8 7 3 1 6 3 8 1 8 5 6 7 2 2 1 0 1 6 3 5 3 7 3 8 9\n 3 6 1 8 1 3 7 0 9 1 6 0 5 8 1 3 5 4 3 1 2 1 1 2 2 1 7 6 9 4 0 0 5 1 6 7 4\n 8 3 2 6 8 2 5 4 5 4 2 9 0 9 8 2 1 3 7 0 6 8 9 4 1 5 0 4 9 9 8 0 1 1 5 2 3\n 2 6 7 7 9 4 0 7 5 9 3 3 7 5 1 9 4 0 0 8 1 4 4 4 8 2 1 8 3 4 8 9 9 0 1 1 5\n 5 3 6 4 1 4 2 3 7 9 9 7 5 6 8 0 2 1 5 1 8 9 6 7 0 1 8 1 7 0 1 0 0 6 3 9 8\n 4 8 9 4 4 4 6 8 3 6 5 7 5 3 9 3 3 6 6 1 3 7 3 5 5 6 7 8 7 1 6 0 7 1 4 6 0\n 9 9 1 4 1 9 8 2 2 5 4 9 7 8 2 7 9 8 1 4 9 1 3 1 4 2 3 3 0 3 9 9 5 3 4 3 7\n 7 3 1 1 8 7 7 9 7 8 6 2 2 1 7 4 1 3 7 2 0 9 5 7 3 0 5 2 9 5 0 7 4 3 9 5 1\n 2 3 1 4 7 2 7 9 8 1 1 5 9 1 7 3 4 4 2 0 3 9 1 6 2 1 6 9 1 0 8 3 1 3 9 1 5\n 2 9 6 0 1 9 0 9 4 9 6 5 9 4 2 7 2 9 7 9 3 7 0 9 2 4 9 3 1 6 3 4 0 7 8 3 6\n 6 6 8 2 3 5 8 1 6 3 3 1 4 2 0 3 6 0 8 1 0 3 1 7 4 0 9 9 4 0 2 6 2 6 7 0 4\n 4 0 1 1 3 9 6 8 8 1 5 3 4 0 6 7 7 0 6 3 9 5 6 9 2 3 6 3 7 6 6 1 9 0 6 6 4\n 9 9 5 1 7 6 0 0 3 2 9 1 5 0 6 1 1 1 0 7 4 6 9 8 9 3 0 9 2 4 3 7 2 4 5 2 9\n 9 9 3 0 3 1 4 7 8 2 7 0 4 7 7 5 5 3 8 6 7 7 3 2 7 5 9 9 8 4 8 1 3 0 6 7 1\n 5 9 3 1 6 3 1 3 4 1 3 2 4 9 7 2 9 0 8 6 5 4 5 7 6 8 4 0 7 8 3 1 6 7 5 9 3\n 1 2 9 8 6 6 3 5 2 8 7 9 6 2 6 2 9 0 5 6 9 7 1 2 5 5 5 1 5 5 0 6 5 8 1 1 3\n 4 2 9 2 4 7 1 8 6 1 8 7 1 6 1 4 9 5 4 8 7 4 0 7 3 9 7 8 9 6 8 7 0 0 7 0 8\n 0 6 8 7 3 0 9 0 9 7 2 0 3 1 6 6 0 1 8 6 8 6 9 8 8 9 9 6 6 8 4 4 8 1 0 5 6\n 9 4 9 4 1 6 9 9 0 4 4 5 1 4 6 1 0 2 8 5 1 6 8 1 6 8 5 6 8 9 8 2 4 4 3 9 7\n 7 4 3 9 2 2 0 4 8 8 6 6 3 5 9 1 1 7 6 3 7 8 3 0 3 1 2 6 1 2 4 0 5 8 0 1 2\n 2 5 1 4 9 0 7 2 7 2 5 7 4 3 0 8 0 8 0 4 2 1 9 8 5 0 8 2 1 0 9 9 4 0 7 4 8\n 0 5 7 2 6 3 3 6 9 2 3 2 5 6 2 6 7 1 2 7 3 5 8 2 3 8 8 0 2 0 0 9 6 3 5 8 7\n 1 2 0 7 2 6 3 3 5 4 8 5 5 1 0 0 1 6 9 0 1 5 7 5 8 3 1 7 2 9 2 4 4 8 4 5 1\n 0] [5 2 6 5 4 8 7 6 0 7 4 4 8 0 6 0 5 7 2 1 3 0 8 1 8 3 2 4 2 9 5 2 9 3 4 7 6\n 3 0 3 6 4 2 4 7 6 5 7 1 7 1 0 9 8 3 8 0 6 6 8 8 0 2 8 8 1 8 5 0 9 9 6 5 2\n 6 9 9 2 3 0 6 0 9 8 9 2 0 7 5 6 6 3 6 8 0 5 0 6 6 6 1 5 5 7 8 3 9 1 6 7 4\n 0 8 9 3 8 0 3 1 2 4 6 4 5 5 4 0 5 0 9 4 0 7 0 9 4 7 0 7 0 0 4 1 0 1 9 7 5\n 7 9 7 7 7 1 1 4 0 2 4 4 5 7 3 1 6 3 8 1 8 5 6 7 2 2 4 0 1 6 5 5 3 7 3 8 9\n 3 6 1 8 8 3 7 0 9 1 6 0 5 8 1 5 8 4 3 1 2 1 1 2 2 1 7 4 9 4 0 0 5 5 6 7 2\n 8 3 2 6 8 2 5 4 5 4 0 9 0 9 8 8 1 3 7 0 6 8 4 4 1 5 0 9 9 4 8 0 1 7 5 2 3\n 2 6 7 7 9 4 0 9 5 9 3 3 7 5 1 9 4 0 0 8 1 4 9 4 5 2 1 8 5 4 8 9 4 0 1 1 3\n 3 3 6 4 1 4 2 3 7 9 9 7 5 6 0 0 2 1 5 1 8 9 6 7 0 1 1 1 7 2 1 0 0 6 3 9 8\n 4 6 9 4 4 4 6 8 8 6 0 7 5 3 9 3 3 6 6 1 3 7 2 5 3 6 7 8 7 1 6 0 7 1 4 6 6\n 9 9 1 9 1 9 5 2 2 5 4 9 7 8 2 3 2 8 1 4 9 1 3 1 4 9 3 3 0 3 9 9 5 5 4 3 7\n 9 3 1 1 8 7 9 9 5 8 6 2 2 1 7 7 6 3 7 2 0 9 5 7 3 0 5 3 9 5 6 9 4 3 4 5 1\n 2 3 1 4 7 2 7 7 4 9 1 5 4 6 4 3 4 4 2 0 3 9 1 6 8 1 6 9 1 3 8 3 1 3 4 1 6\n 2 9 6 0 1 9 0 9 4 9 6 5 9 4 2 7 2 9 7 9 3 7 0 9 6 4 9 5 1 8 3 4 0 7 8 3 6\n 6 6 8 2 3 3 5 1 6 3 3 1 4 2 0 3 6 0 9 5 0 3 1 7 4 0 9 9 4 7 2 2 6 6 7 0 7\n 4 0 1 1 2 9 2 8 8 1 8 3 2 3 6 7 7 0 6 8 9 5 6 9 2 3 6 3 7 6 6 1 9 0 6 6 4\n 9 9 5 1 7 6 0 0 3 7 9 1 5 0 6 1 1 1 0 7 4 6 9 8 9 3 0 4 2 7 3 7 2 4 5 2 9\n 9 9 3 4 3 1 4 7 8 2 7 0 4 7 7 2 5 3 8 6 7 3 2 2 7 5 9 9 2 4 8 1 3 0 6 7 1\n 5 9 3 1 2 5 1 8 4 1 3 2 4 7 7 2 9 0 8 6 5 4 0 7 8 8 4 0 7 8 3 1 6 7 5 9 3\n 1 2 9 8 5 6 8 5 2 8 7 9 6 2 6 2 9 0 5 6 9 7 1 2 5 5 5 1 5 5 0 2 5 8 5 1 3\n 9 2 9 8 4 7 1 8 6 1 8 7 1 6 1 9 4 3 4 8 7 2 0 7 3 9 7 8 9 6 3 7 2 0 7 0 8\n 9 6 8 7 9 0 9 0 9 7 3 4 3 1 6 8 0 1 8 6 5 2 9 8 8 9 9 6 8 8 4 4 8 1 0 8 6\n 9 4 9 4 1 6 9 9 0 4 4 5 1 4 6 1 0 2 3 5 1 6 8 1 6 8 5 6 8 9 3 2 4 4 3 4 7\n 7 4 5 9 2 3 0 4 2 8 6 6 0 5 9 1 1 7 6 3 7 8 3 0 3 2 3 6 1 2 4 0 5 4 0 1 2\n 9 5 1 4 9 0 7 2 7 5 5 7 4 3 0 8 0 8 0 9 2 1 9 8 5 0 8 2 6 0 9 9 4 0 7 4 8\n 0 5 7 2 6 8 3 6 9 2 3 2 5 6 2 6 7 1 2 9 2 5 8 2 3 8 8 0 2 0 0 9 6 3 5 8 7\n 1 2 0 7 2 6 3 3 5 4 5 5 0 1 0 0 1 6 4 0 1 5 7 6 8 3 1 2 2 4 2 4 4 8 4 5 5\n 0]\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.84"},"metadata":{}}]},{"cell_type":"markdown","source":"Still 84% accuracy, so our model generalized from the training data pretty well.","metadata":{}}]}